{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2_DIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2btJHCqSLuRBeSQy3cDbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abh1-Shek/StyleGANs_DIP/blob/main/StyleGAN2_DIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DIP Project"
      ],
      "metadata": {
        "id": "_pbBJQ91mc_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# warning: plz enable gpu in colab before running anything\n",
        "# connect your drive through this cell so you don't need to worry about data being lost\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# please keep the structure of gdrive like this\n",
        "# DIP_project_gan\n",
        "#   gan\n",
        "#     dataset\n",
        "#     experiments\n",
        "#     images\n",
        "#       keep the images you want to train on here"
      ],
      "metadata": {
        "id": "RBcKCOaimhGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original code can be found here\n",
        "# https://github.com/jeffheaton/present/blob/master/youtube/gan/colab_gan_train.ipynb"
      ],
      "metadata": {
        "id": "Zpy4usk1ny4R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#StyleGAN2 works on old version of pytorch\n",
        "!pip install torch==1.8.1 torchvision==0.9.1  #downgrading pytorch\n",
        "\n",
        "#cloning the code of StyleGAN\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install ninja\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3VA-5tZozqW",
        "outputId": "f98a93c7-c4a6-4393-def2-ee49ac695669"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1\n",
            "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 542 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1 torchvision-0.9.1\n",
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 8.50 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since styleGAN work on images with size in power of 2 so this code does the same thing of resizing the images\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "path = '/content/gdrive/MyDrive/DIP_project_gan/gan/images/celebs/'\n",
        "\n",
        "\n",
        "im_size = 128   # Input image resolution must be a power-of-two otherwise you will get error. \n",
        "                 #Pixel resolutions that are powers of 2 (512 x 512, 1024 x 1024, 2048 x 2048, etc).\n",
        "\n",
        "images = []\n",
        "\n",
        "for file in os.listdir(path):\n",
        "        img = cv2.imread(path + '/' + file)  # reading that image as array\n",
        "        img = cv2.resize(img, (im_size, im_size))\n",
        "        print(img.shape)\n",
        "        images.append(img)\n",
        "        # Save the image in Output Folder\n",
        "        cv2.imwrite('/content/gdrive/MyDrive/DIP_project_gan/gan/images/resized_celebs/' + str(file) + '_resized.jpg', img)"
      ],
      "metadata": {
        "id": "yijWF4sQrdA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/stylegan2-ada-pytorch/dataset_tool.py --source /content/gdrive/MyDrive/DIP_project_gan/gan/images/resized_celebs --dest /content/gdrive/MyDrive/DIP_project_gan/gan/dataset/celebs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mno-asNpk6I",
        "outputId": "d3f5d408-d117-454e-c49a-0f1fa3156f70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/10 [00:00<?, ?it/s]\r100% 10/10 [00:00<00:00, 99.25it/s]\r100% 10/10 [00:00<00:00, 98.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell will initiate the traing process\n",
        "import os\n",
        "\n",
        "EXPERIMENTS = \"/content/gdrive/MyDrive/DIP_project_gan/gan/experiments\"\n",
        "DATA = \"/content/gdrive/MyDrive/DIP_project_gan/gan/dataset/celebs\"\n",
        "SNAP = 10\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py --snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "uQlIRD-rsj-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# command for resuming the training process\n",
        "!/usr/bin/python3 /content/stylegan2-ada-pytorch/train.py --snap 25 --resume /content/drive/MyDrive/data/gan/experiments/00007-circuit-auto1/network-snapshot-000500.pkl --outdir /content/drive/MyDrive/data/gan/experiments --data /content/drive/MyDrive/data/gan/dataset/circuit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_4XULLmtN6Y",
        "outputId": "8aeaded3-b103-4a38-91bd-d1e75ffe0076"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/gdrive/MyDrive/data/DIP_project_gan/gan/dataset/celebs': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using pretrained model\n",
        "# to run this cell you need to have Nvidia GPU and\n",
        "# also you need to clone the styleGAN first and then make a folder named output and then run this command\n",
        "!python /content/stylegan2-ada-pytorch/generate.py --outdir=/content/output --trunc=1 --seeds=0-10 --class=2 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bJbS0dMvJfT",
        "outputId": "60988a6c-4dc6-4f45-f335-28aa28e859ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\"...\n",
            "Generating image for seed 0 (0/11) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 1 (1/11) ...\n",
            "Generating image for seed 2 (2/11) ...\n",
            "Generating image for seed 3 (3/11) ...\n",
            "Generating image for seed 4 (4/11) ...\n",
            "Generating image for seed 5 (5/11) ...\n",
            "Generating image for seed 6 (6/11) ...\n",
            "Generating image for seed 7 (7/11) ...\n",
            "Generating image for seed 8 (8/11) ...\n",
            "Generating image for seed 9 (9/11) ...\n",
            "Generating image for seed 10 (10/11) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4FaW72KO-rp_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}